{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "\n",
    "local_zip=\"./tmp/horse-or-human.zip\"\n",
    "zip_ref=zipfile.ZipFile(local_zip,\"r\")\n",
    "zip_ref.extractall(\"./tmp/horse-or-human\")\n",
    "zip_ref.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_horse_dir=os.path.join('./tmp/horse-or-human/horses')\n",
    "train_human_dir=os.path.join('./tmp/horse-or-human/humans')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['horse01-0.png', 'horse01-1.png', 'horse01-2.png', 'horse01-3.png', 'horse01-4.png', 'horse01-5.png', 'horse01-6.png', 'horse01-7.png', 'horse01-8.png', 'horse01-9.png']\n",
      "['human01-00.png', 'human01-01.png', 'human01-02.png', 'human01-03.png', 'human01-04.png', 'human01-05.png', 'human01-06.png', 'human01-07.png', 'human01-08.png', 'human01-09.png']\n"
     ]
    }
   ],
   "source": [
    "train_horse_names=os.listdir(train_horse_dir)\n",
    "print(train_horse_names[:10])\n",
    "train_human_names=os.listdir(train_human_dir)\n",
    "print(train_human_names[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total horse images :  500\n",
      "total_human_images :  527\n"
     ]
    }
   ],
   "source": [
    "print(\"total horse images : \",len(train_horse_names))\n",
    "print(\"total_human_images : \",len(train_human_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "%matplotlib inline\n",
    "\n",
    "nrows=4\n",
    "ncols=4\n",
    "pic_index=0\n",
    "\n",
    "fig=plt.gcf()\n",
    "fig.set_size_inches(ncols*4,nrows*4)\n",
    "pic_index+=8\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Conv2D,MaxPooling2D,Flatten,Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=keras.models.Sequential([\n",
    "    Conv2D(16,(3,3),activation='relu',input_shape=(300,300,3)),\n",
    "    MaxPooling2D(2,2),\n",
    "    Conv2D(32,(3,3),activation=\"relu\"),\n",
    "    MaxPooling2D(2,2),\n",
    "    Conv2D(64,(3,3),activation=\"relu\"),\n",
    "    MaxPooling2D(2,2),\n",
    "    Conv2D(64,(3,3),activation=\"relu\"),\n",
    "    MaxPooling2D(2,2),\n",
    "    Conv2D(64,(3,3),activation=\"relu\"),\n",
    "    MaxPooling2D(2,2),\n",
    "    Flatten(),\n",
    "    Dense(512,activation=\"relu\"),\n",
    "    Dense(1,activation=\"sigmoid\")\n",
    "    \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 298, 298, 16)      448       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 149, 149, 16)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 147, 147, 32)      4640      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 73, 73, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 71, 71, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 35, 35, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 33, 33, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 14, 14, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 3136)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               1606144   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 1,704,097\n",
      "Trainable params: 1,704,097\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import RMSprop\n",
    "\n",
    "model.compile(loss=\"binary_crossentropy\",\n",
    "             optimizer=RMSprop(lr=0.001),\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1027 images belonging to 2 classes.\n",
      "Found 256 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen=ImageDataGenerator(rescale=1./255)\n",
    "validation_datagen=ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator=train_datagen.flow_from_directory(\n",
    "    './tmp/horse-or-human/',\n",
    "    target_size=(300,300),\n",
    "    batch_size=128,\n",
    "    class_mode=\"binary\")\n",
    "\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "        './tmp/validation-horse-or-human/',  \n",
    "        target_size=(300, 300),\n",
    "        batch_size=32,\n",
    "        class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 8 steps, validate for 8 steps\n",
      "Epoch 1/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0615 16:21:37.245184 15584 deprecation.py:323] From c:\\users\\home\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\ops\\nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 131s 16s/step - loss: 0.9059 - accuracy: 0.5068 - val_loss: 0.6698 - val_accuracy: 0.5000\n",
      "Epoch 2/15\n",
      "8/8 [==============================] - 153s 19s/step - loss: 0.7896 - accuracy: 0.6741 - val_loss: 0.3816 - val_accuracy: 0.8398\n",
      "Epoch 3/15\n",
      "8/8 [==============================] - 125s 16s/step - loss: 0.5666 - accuracy: 0.7953 - val_loss: 0.3258 - val_accuracy: 0.8672\n",
      "Epoch 4/15\n",
      "8/8 [==============================] - 67s 8s/step - loss: 0.3414 - accuracy: 0.8420 - val_loss: 0.8608 - val_accuracy: 0.7734\n",
      "Epoch 5/15\n",
      "8/8 [==============================] - 69s 9s/step - loss: 0.2102 - accuracy: 0.9043 - val_loss: 0.7888 - val_accuracy: 0.7344\n",
      "Epoch 6/15\n",
      "8/8 [==============================] - 80s 10s/step - loss: 0.1573 - accuracy: 0.9377 - val_loss: 1.3791 - val_accuracy: 0.8008\n",
      "Epoch 7/15\n",
      "8/8 [==============================] - 81s 10s/step - loss: 0.4722 - accuracy: 0.8209 - val_loss: 1.3758 - val_accuracy: 0.7891\n",
      "Epoch 8/15\n",
      "8/8 [==============================] - 68s 8s/step - loss: 0.0862 - accuracy: 0.9622 - val_loss: 1.5109 - val_accuracy: 0.8047\n",
      "Epoch 9/15\n",
      "8/8 [==============================] - 67s 8s/step - loss: 0.0646 - accuracy: 0.9711 - val_loss: 1.6686 - val_accuracy: 0.8047\n",
      "Epoch 10/15\n",
      "8/8 [==============================] - 71s 9s/step - loss: 0.0243 - accuracy: 0.9889 - val_loss: 1.0138 - val_accuracy: 0.8359\n",
      "Epoch 11/15\n",
      "8/8 [==============================] - 70s 9s/step - loss: 0.6528 - accuracy: 0.9499 - val_loss: 0.9793 - val_accuracy: 0.8359\n",
      "Epoch 12/15\n",
      "8/8 [==============================] - 71s 9s/step - loss: 0.0641 - accuracy: 0.9800 - val_loss: 1.5753 - val_accuracy: 0.8047\n",
      "Epoch 13/15\n",
      "8/8 [==============================] - 68s 8s/step - loss: 0.0097 - accuracy: 0.9978 - val_loss: 1.6426 - val_accuracy: 0.8242\n",
      "Epoch 14/15\n",
      "8/8 [==============================] - 76s 9s/step - loss: 0.1001 - accuracy: 0.9639 - val_loss: 2.7480 - val_accuracy: 0.7344\n",
      "Epoch 15/15\n",
      "8/8 [==============================] - 67s 8s/step - loss: 0.0395 - accuracy: 0.9811 - val_loss: 0.8738 - val_accuracy: 0.8789\n"
     ]
    }
   ],
   "source": [
    "history=model.fit(\n",
    "train_generator,\n",
    "steps_per_epoch=8,\n",
    "epochs=15,\n",
    "verbose=1,\n",
    "validation_data=validation_generator,\n",
    "validation_steps=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.preprocessing import image\n",
    "\n",
    "file_path=\"\"\n",
    "img=image.load_img(file_path,target_size=(300,300))\n",
    "x=image.img_to_array(img)\n",
    "x=np.expand_dims(x,axis=0)\n",
    "\n",
    "images=np.vstack([x])\n",
    "classes=model.predict(images,batch_size=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
